{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine translation using Attention architecture\n",
    "\n",
    "This notebook demonstrate the machine translation from english to hindi language using encoder-decoder architecture using attention architecture. Though the same model can be used for translating input into any other language"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-requisites\n",
    "\n",
    "- Download the data: http://www.manythings.org/anki/\n",
    "- Download the word vectors: http://nlp.stanford.edu/data/glove.6B.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "import random\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, LSTM, GRU, Dense, Embedding, Bidirectional, RepeatVector\n",
    "from keras.layers import Activation, Concatenate, Dot, Lambda\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import keras.backend as K\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "random.seed(1)\n",
    "tf.set_random_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax_over_time(x):\n",
    "    assert(K.ndim(x) > 2)\n",
    "    e = K.exp(x- K.max(x, axis=1, keepdims=True))\n",
    "    s = K.sum(e, axis=1, keepdims=True)\n",
    "    return e/s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0924 10:00:07.183930 140482400499520 deprecation_wrapper.py:119] From /home/agoel/anaconda3/envs/ML/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "W0924 10:00:07.185532 140482400499520 deprecation_wrapper.py:119] From /home/agoel/anaconda3/envs/ML/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "W0924 10:00:07.186332 140482400499520 deprecation_wrapper.py:119] From /home/agoel/anaconda3/envs/ML/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:186: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "W0924 10:00:07.197932 140482400499520 deprecation_wrapper.py:119] From /home/agoel/anaconda3/envs/ML/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if len(K.tensorflow_backend._get_available_gpus()) > 0:\n",
    "    from keras.layers import CuDNNLSTM as LSTM\n",
    "    from keras.layers import CuDNNGRU as GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "\n",
    "BATCH_SIZE=64              # Batch size for training.\n",
    "EPOCHS = 50                # Number of epochs to train for.\n",
    "LATENT_DIM = 256           # Latent dimensionality of the encoding space.\n",
    "LATENT_DIM_DECODER = 256   # Latent dimensionaliuty for the decoder\n",
    "NUM_SAMPLES = 10000        # Number of samples to train on\n",
    "MAX_SEQUENCE_LENGTH = 100\n",
    "MAX_NUM_WORDS = 20000\n",
    "EMBEDDING_DIM = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Where we will store the data\n",
    "input_texts = []          # sentence in original language\n",
    "target_texts = []         # sentence in target language\n",
    "target_texts_inputs = []  # sentence in target language offset by 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 2808\n"
     ]
    }
   ],
   "source": [
    "t = 0\n",
    "for line in open('data/hin-eng/hin.txt'):\n",
    "    # only keep a limited number of samples.\n",
    "    t += 1\n",
    "    if t > NUM_SAMPLES:\n",
    "        break\n",
    "        \n",
    "    # input and target are separated by tab\n",
    "    if '\\t' not in line:\n",
    "        continue\n",
    "        \n",
    "    # split up the input and translation\n",
    "    input_text, translation = line.rstrip().split('\\t')\n",
    "    \n",
    "    # make the target input and output using teacher forcing\n",
    "    target_text = translation + ' <eos>'\n",
    "    target_text_input = '<sos> ' + translation\n",
    "    \n",
    "    input_texts.append(input_text)\n",
    "    target_texts.append(target_text)\n",
    "    target_texts_inputs.append(target_text_input)\n",
    "    \n",
    "print(\"Number of samples:\", len(input_texts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize the inputs (Convert the sentences (string) into integers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_inputs = Tokenizer(num_words = MAX_NUM_WORDS)\n",
    "tokenizer_inputs.fit_on_texts(input_texts)\n",
    "input_sequences = tokenizer_inputs.texts_to_sequences(input_texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word to integer mapping for input text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2388 unique input tokens.\n",
      "i: 2\n",
      "to: 3\n",
      "you: 4\n",
      "is: 5\n",
      "a: 6\n",
      "he: 7\n",
      "of: 8\n",
      "in: 9\n",
      "my: 10\n"
     ]
    }
   ],
   "source": [
    "# get the word to index/integer mapping for input language\n",
    "word2idx_inputs = tokenizer_inputs.word_index\n",
    "print('Found {} unique input tokens.'.format(len(word2idx_inputs)))\n",
    "\n",
    "for x in list(word2idx_inputs)[1:10]:\n",
    "    print('{}: {}'.format(x, word2idx_inputs[x]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_len_input: 22\n"
     ]
    }
   ],
   "source": [
    "# Determine maximum length input sequence\n",
    "max_len_input = max(len(s) for s in input_sequences)\n",
    "\n",
    "print('max_len_input:', max_len_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize the output (Convert the sentences (string) into integers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We don't filter out special characters, otherwise <eos> and <sos> won't appear.\n",
    "tokenizer_outputs = Tokenizer(num_words=MAX_NUM_WORDS, filters='')\n",
    "# This is an inefficient way as we are tokenizing it on the same data (target_texts and target_texts_input)\n",
    "# just offset by <sos> and <eos>word2idx_outputs\n",
    "tokenizer_outputs.fit_on_texts(target_texts + target_texts_inputs)\n",
    "\n",
    "target_sequences = tokenizer_outputs.texts_to_sequences(target_texts)\n",
    "target_sequences_input = tokenizer_outputs.texts_to_sequences(target_texts_inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word to integer mapping for output texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3138 unique output tokens.\n",
      "<sos>: 2\n",
      "है।: 3\n",
      "में: 4\n",
      "नहीं: 5\n",
      "मैं: 6\n",
      "वह: 7\n",
      "से: 8\n",
      "के: 9\n",
      "मुझे: 10\n"
     ]
    }
   ],
   "source": [
    "# get the word to index mapping for output/translated language\n",
    "word2idx_outputs = tokenizer_outputs.word_index\n",
    "print('Found %s unique output tokens.' %len(word2idx_outputs))\n",
    "\n",
    "for x in list(word2idx_outputs)[1:10]:\n",
    "    print('{}: {}'.format(x, word2idx_outputs[x]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_words_output: 3139\n",
      "Maximum length of target/translated text is: 26\n"
     ]
    }
   ],
   "source": [
    "# store number of output words for later. remember to add 1 since indexing starts at 1\n",
    "num_words_output = len(word2idx_outputs) + 1\n",
    "print('num_words_output:', num_words_output)\n",
    "\n",
    "# determine the maximum length output sequence\n",
    "max_len_target = max(len(s) for s in target_sequences)\n",
    "print ('Maximum length of target/translated text is:', max_len_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pad Sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder_inputs.shape: (2808, 22)\n",
      "encoder_inputs[0]: [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0 1274]\n"
     ]
    }
   ],
   "source": [
    "encoder_inputs = pad_sequences(input_sequences, maxlen=max_len_input)\n",
    "print('encoder_inputs.shape:', encoder_inputs.shape)\n",
    "print('encoder_inputs[0]:', encoder_inputs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decoder_inputs.shape: (2808, 26)\n",
      "decoder_inputs[0]: [   2 1486    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0]\n"
     ]
    }
   ],
   "source": [
    "decoder_inputs = pad_sequences(target_sequences_input, maxlen=max_len_target, padding='post')\n",
    "# 26 is the maximum length of the sentence in the translated data in the training set\n",
    "print('decoder_inputs.shape:', decoder_inputs.shape)\n",
    "print('decoder_inputs[0]:', decoder_inputs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decoder_targets.shape: (2808, 26)\n",
      "decoder_targets[0]: [1486    1    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0]\n"
     ]
    }
   ],
   "source": [
    "decoder_targets = pad_sequences(target_sequences, maxlen=max_len_target, padding='post')\n",
    "print('decoder_targets.shape:', decoder_targets.shape)\n",
    "print('decoder_targets[0]:', decoder_targets[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load pre-trained word vectors - Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading word vectors\n",
      "Found 400000 word vectors.\n",
      "Embedding dimensions:  (100,)\n"
     ]
    }
   ],
   "source": [
    "print('Loading word vectors')\n",
    "word2vec = {}\n",
    "# Load word vector of 100 dimensions.\n",
    "with open (os.path.join('Embeddings/glove.6B/glove.6B.%sd.txt' %EMBEDDING_DIM)) as f:\n",
    "    for line in f:\n",
    "        # split at spaces\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        #np.asarray Converts the input to an array.\n",
    "        vec = np.asarray(values[1:], dtype='float32')\n",
    "        word2vec[word] = vec\n",
    "        \n",
    "print('Found %s word vectors.' %len(word2vec))\n",
    "print('Embedding dimensions: ', word2vec['the'].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Embedding matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filling pre-trained embeddings\n",
      "num_words: 2389\n",
      "Shape of Embeddings matrix:  (2389, 100)\n"
     ]
    }
   ],
   "source": [
    "print('Filling pre-trained embeddings')\n",
    "# MAX_NUM_WORDS = 20000\n",
    "num_words = min(MAX_NUM_WORDS, len(word2idx_inputs) + 1)\n",
    "embedding_matrix = np.zeros((num_words, EMBEDDING_DIM))\n",
    "for word, i in word2idx_inputs.items():\n",
    "    if i < MAX_NUM_WORDS:\n",
    "        embedding_vector = word2vec.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            # words not foun20000d in the embedding index will all be zero\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "\n",
    "print('num_words:', num_words)\n",
    "# 2389 words each of 100 dimensions\n",
    "print('Shape of Embeddings matrix: ', embedding_matrix.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0924 10:00:17.899603 140482400499520 deprecation_wrapper.py:119] From /home/agoel/anaconda3/envs/ML/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "embedding_layer = Embedding(num_words, \n",
    "                           EMBEDDING_DIM,\n",
    "                           weights = [embedding_matrix],\n",
    "                           input_length = max_len_input,\n",
    "                           #trainable=true\n",
    "                           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create targets, since we cannot use sparse\n",
    "# categorical cross entropy when we have sequences\n",
    "decoder_targets_one_hot = np.zeros(\n",
    "  (\n",
    "    len(input_texts),\n",
    "    max_len_target,\n",
    "    num_words_output\n",
    "  ),\n",
    "  dtype='float32'\n",
    ")\n",
    "\n",
    "# assign the values\n",
    "for i, d in enumerate(decoder_targets):\n",
    "    for t, word in enumerate(d):\n",
    "        decoder_targets_one_hot[i, t, word] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build encoder-decoder LSTM with Attention model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0924 10:00:18.324268 140482400499520 deprecation.py:506] From /home/agoel/anaconda3/envs/ML/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "encoder_inputs_placeholder = Input(shape=(max_len_input, ))\n",
    "x = embedding_layer(encoder_inputs_placeholder)\n",
    "\n",
    "# Bidirectional LSTM\n",
    "encoder_lstm = Bidirectional(LSTM(\n",
    "    LATENT_DIM,\n",
    "    return_sequences=True,\n",
    "    dropout=0.5\n",
    "))\n",
    "\n",
    "encoder_outputs = encoder_lstm(x)\n",
    "\n",
    "# setup the decoder, using [h,c] as initial state\n",
    "decoder_inputs_placeholder = Input(shape=(max_len_target, ))\n",
    "\n",
    "# this word embedding will not use pre-trained vectors although we could\n",
    "decoder_embedding_layer = Embedding(num_words_output, EMBEDDING_DIM)\n",
    "decoder_inputs_x = decoder_embedding_layer(decoder_inputs_placeholder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attention layer needs to be global because they will be repeated Ty times at the decoder\n",
    "\n",
    "attn_repeat_layer = RepeatVector(max_len_input)\n",
    "attn_concat_layer = Concatenate(axis=-1)\n",
    "attn_dense1 = Dense(10, activation = 'tanh')\n",
    "attn_dense2 = Dense(1, activation = softmax_over_time)\n",
    "attn_dot = Dot(axes=1) # to perform the weighted sum of alpha[t] * h[t]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_step_attention(h, st_1):\n",
    "    st_1 = attn_repeat_layer(st_1)\n",
    "    \n",
    "    x = attn_concat_layer([h, st_1])\n",
    "    \n",
    "    # Neural net first dense layer\n",
    "    x = attn_dense1(x)\n",
    "    \n",
    "    # Neural net second layer with special softmax over time\n",
    "    alphas = attn_dense2(x)\n",
    "    \n",
    "    context = attn_dot([alphas, h])\n",
    "    \n",
    "    return context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_lstm = LSTM(\n",
    "        LATENT_DIM_DECODER, \n",
    "        return_state=True,\n",
    "        dropout = 0.5\n",
    "    )\n",
    "\n",
    "decoder_dense = Dense(num_words_output, activation = 'softmax')\n",
    "\n",
    "initial_s = Input(shape=(LATENT_DIM_DECODER, ), name='s0')\n",
    "initial_c = Input(shape=(LATENT_DIM_DECODER, ), name='c0')\n",
    "context_last_word_concat_layer = Concatenate(axis=2)\n",
    "\n",
    "# unlike encoder-decoder without Attention model, we don't get the output all in one step\n",
    "# Instead we need to do Ty steps and in each of those steps, we need to consider all Tx h's\n",
    "\n",
    "# s,c will be re-assigned in each iteration of the loop.\n",
    "s = initial_s\n",
    "c = initial_c\n",
    "\n",
    "# Collect output in a list at first\n",
    "outputs = []\n",
    "\n",
    "for t in range (max_len_target): #Ty times\n",
    "    \n",
    "    # get the context using attention\n",
    "    context = one_step_attention(encoder_outputs, s)\n",
    "    \n",
    "    # We need a different layer for each time step\n",
    "    selector = Lambda(lambda x: x[:, t:t+1])\n",
    "    xt = selector(decoder_inputs_x)\n",
    "    \n",
    "    # Combine\n",
    "    decoder_lstm_input = context_last_word_concat_layer([context, xt])\n",
    "    \n",
    "    # pass the combined [context, last word] into LSTM along with [s, c].\n",
    "    # get the new [s, c] and output\n",
    "    o, s, c = decoder_lstm(decoder_lstm_input, initial_state=[s, c])\n",
    "    \n",
    "    # final desnse layer to get next word prediction\n",
    "    decoder_outputs = decoder_dense(o)\n",
    "    outputs.append(decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.shape: (26, ?, 3139)\n",
      "x.shape after permute_dimension: (?, 26, 3139)\n",
      "x.shape: (26, ?, 3139)\n",
      "x.shape after permute_dimension: (?, 26, 3139)\n"
     ]
    }
   ],
   "source": [
    "# 'outputs' is now a list of length Ty\n",
    "def stack_and_transpose(x):\n",
    "    # x is a list of length T, each element is a batch_size * output_vocab_size tensor\n",
    "    x = K.stack(x) # T * batch_size * output_vocab_size tensor\n",
    "    print('x.shape:', x.shape)\n",
    "    x = K.permute_dimensions(x, pattern=(1, 0, 2))  # batch_size * T * outputz_vocab_size tensor\n",
    "    print('x.shape after permute_dimension:', x.shape)\n",
    "    return x\n",
    "\n",
    "# Make it a layer\n",
    "stacker = Lambda(stack_and_transpose)\n",
    "outputs = stacker(outputs)\n",
    "\n",
    "# Create the model object\n",
    "model = Model(\n",
    "          inputs = [\n",
    "               encoder_inputs_placeholder, \n",
    "               decoder_inputs_placeholder,\n",
    "               initial_s,\n",
    "               initial_c\n",
    "          ],\n",
    "          outputs = outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0924 10:00:26.797118 140482400499520 deprecation_wrapper.py:119] From /home/agoel/anaconda3/envs/ML/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.compile(\n",
    "        optimizer = 'rmsprop',\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NUM_SAMPLES: 10000, LATENT_DIM_DECODER: 256\n",
      "encoder_inputs.shape: (2808, 22), decoder_inputs.shape:(2808, 26)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0924 10:00:29.283782 140482400499520 deprecation.py:323] From /home/agoel/anaconda3/envs/ML/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2246 samples, validate on 562 samples\n",
      "Epoch 1/50\n",
      "2246/2246 [==============================] - 86s 38ms/step - loss: 2.4828 - acc: 0.7097 - val_loss: 2.9204 - val_acc: 0.5831\n",
      "Epoch 2/50\n",
      "2246/2246 [==============================] - 33s 15ms/step - loss: 1.7254 - acc: 0.7386 - val_loss: 2.7962 - val_acc: 0.6064\n",
      "Epoch 3/50\n",
      "2246/2246 [==============================] - 32s 14ms/step - loss: 1.5715 - acc: 0.7528 - val_loss: 2.7619 - val_acc: 0.6224\n",
      "Epoch 4/50\n",
      "2246/2246 [==============================] - 32s 14ms/step - loss: 1.4804 - acc: 0.7700 - val_loss: 2.6959 - val_acc: 0.6245\n",
      "Epoch 5/50\n",
      "2246/2246 [==============================] - 36s 16ms/step - loss: 1.4275 - acc: 0.7761 - val_loss: 2.7027 - val_acc: 0.6277\n",
      "Epoch 6/50\n",
      "2246/2246 [==============================] - 37s 16ms/step - loss: 1.3752 - acc: 0.7804 - val_loss: 2.6864 - val_acc: 0.6324\n",
      "Epoch 7/50\n",
      "2246/2246 [==============================] - 36s 16ms/step - loss: 1.3266 - acc: 0.7859 - val_loss: 2.6997 - val_acc: 0.6333\n",
      "Epoch 8/50\n",
      "2246/2246 [==============================] - 35s 16ms/step - loss: 1.2783 - acc: 0.7899 - val_loss: 2.6241 - val_acc: 0.6410\n",
      "Epoch 9/50\n",
      "2246/2246 [==============================] - 35s 16ms/step - loss: 1.2329 - acc: 0.7945 - val_loss: 2.6613 - val_acc: 0.6384\n",
      "Epoch 10/50\n",
      "2246/2246 [==============================] - 36s 16ms/step - loss: 1.1957 - acc: 0.7960 - val_loss: 2.6410 - val_acc: 0.6373\n",
      "Epoch 11/50\n",
      "2246/2246 [==============================] - 35s 16ms/step - loss: 1.1645 - acc: 0.7976 - val_loss: 2.6799 - val_acc: 0.6398\n",
      "Epoch 12/50\n",
      "2246/2246 [==============================] - 34s 15ms/step - loss: 1.1306 - acc: 0.7995 - val_loss: 2.6092 - val_acc: 0.6437\n",
      "Epoch 13/50\n",
      "2246/2246 [==============================] - 34s 15ms/step - loss: 1.1003 - acc: 0.8025 - val_loss: 2.5628 - val_acc: 0.6435\n",
      "Epoch 14/50\n",
      "2246/2246 [==============================] - 35s 15ms/step - loss: 1.0685 - acc: 0.8042 - val_loss: 2.5667 - val_acc: 0.6469\n",
      "Epoch 15/50\n",
      "2246/2246 [==============================] - 36s 16ms/step - loss: 1.0407 - acc: 0.8067 - val_loss: 2.5668 - val_acc: 0.6475\n",
      "Epoch 16/50\n",
      "2246/2246 [==============================] - 35s 16ms/step - loss: 1.0135 - acc: 0.8094 - val_loss: 2.5419 - val_acc: 0.6477\n",
      "Epoch 17/50\n",
      "2246/2246 [==============================] - 36s 16ms/step - loss: 0.9870 - acc: 0.8118 - val_loss: 2.5771 - val_acc: 0.6502\n",
      "Epoch 18/50\n",
      "2246/2246 [==============================] - 35s 16ms/step - loss: 0.9607 - acc: 0.8142 - val_loss: 2.5604 - val_acc: 0.6484\n",
      "Epoch 19/50\n",
      "2246/2246 [==============================] - 35s 16ms/step - loss: 0.9371 - acc: 0.8166 - val_loss: 2.5637 - val_acc: 0.6497\n",
      "Epoch 20/50\n",
      "2246/2246 [==============================] - 37s 16ms/step - loss: 0.9120 - acc: 0.8196 - val_loss: 2.5742 - val_acc: 0.6474\n",
      "Epoch 21/50\n",
      "2246/2246 [==============================] - 35s 16ms/step - loss: 0.8886 - acc: 0.8216 - val_loss: 2.5548 - val_acc: 0.6486\n",
      "Epoch 22/50\n",
      "2246/2246 [==============================] - 35s 16ms/step - loss: 0.8676 - acc: 0.8241 - val_loss: 2.5748 - val_acc: 0.6489\n",
      "Epoch 23/50\n",
      "2246/2246 [==============================] - 36s 16ms/step - loss: 0.8431 - acc: 0.8269 - val_loss: 2.5755 - val_acc: 0.6504\n",
      "Epoch 24/50\n",
      "2246/2246 [==============================] - 36s 16ms/step - loss: 0.8229 - acc: 0.8299 - val_loss: 2.5743 - val_acc: 0.6494\n",
      "Epoch 25/50\n",
      "2246/2246 [==============================] - 36s 16ms/step - loss: 0.8011 - acc: 0.8322 - val_loss: 2.5609 - val_acc: 0.6532\n",
      "Epoch 26/50\n",
      "2246/2246 [==============================] - 35s 16ms/step - loss: 0.7801 - acc: 0.8364 - val_loss: 2.5802 - val_acc: 0.6517\n",
      "Epoch 27/50\n",
      "2246/2246 [==============================] - 35s 16ms/step - loss: 0.7589 - acc: 0.8387 - val_loss: 2.5785 - val_acc: 0.6532\n",
      "Epoch 28/50\n",
      "2246/2246 [==============================] - 35s 16ms/step - loss: 0.7380 - acc: 0.8431 - val_loss: 2.5755 - val_acc: 0.6526\n",
      "Epoch 29/50\n",
      "2246/2246 [==============================] - 35s 16ms/step - loss: 0.7194 - acc: 0.8446 - val_loss: 2.5990 - val_acc: 0.6532\n",
      "Epoch 30/50\n",
      "2246/2246 [==============================] - 35s 16ms/step - loss: 0.6987 - acc: 0.8480 - val_loss: 2.5691 - val_acc: 0.6525\n",
      "Epoch 31/50\n",
      "2246/2246 [==============================] - 35s 16ms/step - loss: 0.6796 - acc: 0.8514 - val_loss: 2.6140 - val_acc: 0.6538\n",
      "Epoch 32/50\n",
      "2246/2246 [==============================] - 35s 16ms/step - loss: 0.6601 - acc: 0.8559 - val_loss: 2.6105 - val_acc: 0.6532\n",
      "Epoch 33/50\n",
      "2246/2246 [==============================] - 35s 15ms/step - loss: 0.6403 - acc: 0.8603 - val_loss: 2.6004 - val_acc: 0.6545\n",
      "Epoch 34/50\n",
      "2246/2246 [==============================] - 37s 16ms/step - loss: 0.6216 - acc: 0.8636 - val_loss: 2.6422 - val_acc: 0.6553\n",
      "Epoch 35/50\n",
      "2246/2246 [==============================] - 35s 16ms/step - loss: 0.6030 - acc: 0.8667 - val_loss: 2.6280 - val_acc: 0.6561\n",
      "Epoch 36/50\n",
      "2246/2246 [==============================] - 39s 17ms/step - loss: 0.5872 - acc: 0.8706 - val_loss: 2.6118 - val_acc: 0.6558\n",
      "Epoch 37/50\n",
      "2246/2246 [==============================] - 36s 16ms/step - loss: 0.5696 - acc: 0.8754 - val_loss: 2.6505 - val_acc: 0.6562\n",
      "Epoch 38/50\n",
      "2246/2246 [==============================] - 36s 16ms/step - loss: 0.5509 - acc: 0.8787 - val_loss: 2.6200 - val_acc: 0.6561\n",
      "Epoch 39/50\n",
      "2246/2246 [==============================] - 35s 16ms/step - loss: 0.5329 - acc: 0.8842 - val_loss: 2.6259 - val_acc: 0.6558\n",
      "Epoch 40/50\n",
      "2246/2246 [==============================] - 36s 16ms/step - loss: 0.5178 - acc: 0.8860 - val_loss: 2.6460 - val_acc: 0.6561\n",
      "Epoch 41/50\n",
      "2246/2246 [==============================] - 35s 16ms/step - loss: 0.5013 - acc: 0.8903 - val_loss: 2.6543 - val_acc: 0.6564\n",
      "Epoch 42/50\n",
      "2246/2246 [==============================] - 36s 16ms/step - loss: 0.4855 - acc: 0.8941 - val_loss: 2.6372 - val_acc: 0.6558\n",
      "Epoch 43/50\n",
      "2246/2246 [==============================] - 40s 18ms/step - loss: 0.4715 - acc: 0.8982 - val_loss: 2.6601 - val_acc: 0.6551\n",
      "Epoch 44/50\n",
      "2246/2246 [==============================] - 36s 16ms/step - loss: 0.4568 - acc: 0.9026 - val_loss: 2.6501 - val_acc: 0.6561\n",
      "Epoch 45/50\n",
      "2246/2246 [==============================] - 36s 16ms/step - loss: 0.4421 - acc: 0.9035 - val_loss: 2.6701 - val_acc: 0.6551\n",
      "Epoch 46/50\n",
      "2246/2246 [==============================] - 35s 15ms/step - loss: 0.4266 - acc: 0.9077 - val_loss: 2.6829 - val_acc: 0.6564\n",
      "Epoch 47/50\n",
      "2246/2246 [==============================] - 35s 15ms/step - loss: 0.4152 - acc: 0.9103 - val_loss: 2.7093 - val_acc: 0.6567\n",
      "Epoch 48/50\n",
      "2246/2246 [==============================] - 34s 15ms/step - loss: 0.4010 - acc: 0.9136 - val_loss: 2.6897 - val_acc: 0.6549\n",
      "Epoch 49/50\n",
      "2246/2246 [==============================] - 34s 15ms/step - loss: 0.3884 - acc: 0.9162 - val_loss: 2.6877 - val_acc: 0.6560\n",
      "Epoch 50/50\n",
      "2246/2246 [==============================] - 35s 15ms/step - loss: 0.3763 - acc: 0.9201 - val_loss: 2.7162 - val_acc: 0.6567\n"
     ]
    }
   ],
   "source": [
    "print('NUM_SAMPLES: {}, LATENT_DIM_DECODER: {}'.format(NUM_SAMPLES, LATENT_DIM_DECODER))\n",
    "print('encoder_inputs.shape: {}, decoder_inputs.shape:{}'.format(encoder_inputs.shape, decoder_inputs.shape))\n",
    "print('decoder_targets_one_hot.shape:', decoder_targets_one_hot.shape)\n",
    "print('batch_size: {}, epochs: {}'.format(BATCH))\n",
    "\n",
    "z = np.zeros((encoder_inputs.shape[0], LATENT_DIM_DECODER)) # initial [s, c]\n",
    "\n",
    "history = model.fit(\n",
    "    [encoder_inputs, decoder_inputs, z, z], decoder_targets_one_hot,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    epochs=EPOCHS,\n",
    "    validation_split=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize accuracy and loss curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, 'ro', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('accuracy')\n",
    "plt.legend()\n",
    "plt.savefig('static/acc_machine_translation_attention.png')\n",
    "plt.show()\n",
    "plt.clf()\n",
    "\n",
    "plt.plot(epochs, loss, 'ro', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('loss')\n",
    "plt.legend()\n",
    "plt.savefig('static/loss_machine_translation_attention.png')\n",
    "plt.show()\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create another model that can take in the RNN state and previous word as input and accept a T=1 sequence.\n",
    "\n",
    "# The encoder will be stand-alone\n",
    "# From this we will get our initial decoder hidden state\n",
    "encoder_model = Model(encoder_inputs_placeholder, encoder_outputs)\n",
    "\n",
    "\n",
    "encoder_outputs_as_input = Input(shape=(max_len_input, LATENT_DIM * 2, ))\n",
    "decoder_inputs_single = Input(shape=(1,))\n",
    "decoder_inputs_single_x = decoder_embedding_layer(decoder_inputs_single)\n",
    "\n",
    "# no need to loop over attention steps this time because there is only one step\n",
    "context = one_step_attention(encoder_outputs_as_input, initial_s)\n",
    "\n",
    "# combine context with last word\n",
    "decoder_lstm_input = context_last_word_concat_layer([context, decoder_inputs_single_x])\n",
    "\n",
    "# lstm and final dense\n",
    "o, s, c = decoder_lstm(decoder_lstm_input, initial_state=[initial_s, initial_c])\n",
    "decoder_outputs = decoder_dense(o)\n",
    "\n",
    "# create the decoder model object\n",
    "decoder_model = Model(\n",
    "  inputs=[\n",
    "    decoder_inputs_single,\n",
    "    encoder_outputs_as_input,\n",
    "    initial_s, \n",
    "    initial_c\n",
    "  ],\n",
    "  outputs=[decoder_outputs, s, c]\n",
    ")\n",
    "\n",
    "# map indexes back into real words\n",
    "# so we can view the results\n",
    "idx2word_eng = {v:k for k, v in word2idx_inputs.items()}\n",
    "idx2word_trans = {v:k for k, v in word2idx_outputs.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "  # Encode the input as state vectors.\n",
    "  enc_out = encoder_model.predict(input_seq)\n",
    "\n",
    "  # Generate empty target sequence of length 1.\n",
    "  target_seq = np.zeros((1, 1))\n",
    "\n",
    "  # Populate the first character of target sequence with the start character.\n",
    "  # NOTE: tokenizer lower-cases all words\n",
    "  target_seq[0, 0] = word2idx_outputs['<sos>']\n",
    "\n",
    "  # if we get this we break\n",
    "  eos = word2idx_outputs['<eos>']\n",
    "\n",
    "  # [s, c] will be updated in each loop iteration\n",
    "  s = np.zeros((1, LATENT_DIM_DECODER))\n",
    "  c = np.zeros((1, LATENT_DIM_DECODER))\n",
    "\n",
    "  # Create the translation\n",
    "  output_sentence = []\n",
    "  for _ in range(max_len_target):\n",
    "    \n",
    "    o, s, c = decoder_model.predict([target_seq, enc_out, s, c])\n",
    " \n",
    "    # output_tokens, h = decoder_model.predict(\n",
    "    #     [target_seq] + states_value\n",
    "    # ) # gru\n",
    "\n",
    "    # Get next word\n",
    "    idx = np.argmax(o.flatten())\n",
    "\n",
    "    # End sentence of EOS\n",
    "    if eos == idx:\n",
    "      break\n",
    "\n",
    "    word = ''\n",
    "    if idx > 0:\n",
    "      word = idx2word_trans[idx]\n",
    "      output_sentence.append(word)\n",
    "\n",
    "    # Update the decoder input\n",
    "    # which is just the word just generated\n",
    "    target_seq[0, 0] = idx\n",
    "\n",
    "  return ' '.join(output_sentence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\n",
      "Input: This tie doesn't go with my suit.\n",
      "Predicted Translation: यह टाई मेरे सूट के साथ जचती नहीं है।\n",
      "Actual translation: यह टाई मेरे सूट के साथ जचती नहीं है। <eos>\n",
      "Continue? [Y/n]Y\n",
      "-\n",
      "Input: There is a strange man at the door.\n",
      "Predicted Translation: मेज़ पर एक अजीब सा है।\n",
      "Actual translation: दरवाज़े पर कोई अजीब सा इनसान है। <eos>\n",
      "Continue? [Y/n]Y\n",
      "-\n",
      "Input: Please make yourself at home.\n",
      "Predicted Translation: इसको अपना घर ही समझो।\n",
      "Actual translation: इसको अपना घर ही समझो। <eos>\n",
      "Continue? [Y/n]Y\n",
      "-\n",
      "Input: I am convinced that he did nothing wrong.\n",
      "Predicted Translation: मुझे नहीं पता कि वह कैसे किया कि क्या कर रहा है।\n",
      "Actual translation: मुझे पूरा विश्वास है कि उसने कोई भी ग़लत काम नहीं किया। <eos>\n",
      "Continue? [Y/n]Y\n",
      "-\n",
      "Input: I am sorry if I disturbed you.\n",
      "Predicted Translation: मैं तुम्हें कुछ ठीक से सुन नहीं पा रहा हूँ।\n",
      "Actual translation: माफ़ कीजिएगा अगर मैंने आपको परेशान किया तो। <eos>\n",
      "Continue? [Y/n]Y\n",
      "-\n",
      "Input: Who made this cake?\n",
      "Predicted Translation: यह किताब किसने बनाया है?\n",
      "Actual translation: यह केक किसने बनाया है? <eos>\n",
      "Continue? [Y/n]n\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "  # Do some test translations\n",
    "  i = np.random.choice(len(input_texts))\n",
    "  input_seq = encoder_inputs[i:i+1]\n",
    "  translation = decode_sequence(input_seq)\n",
    "  print('-')\n",
    "  print('Input:', input_texts[i])\n",
    "  print('Predicted Translation:', translation)\n",
    "  print('Actual translation:', target_texts[i])\n",
    "    \n",
    "  ans = input(\"Continue? [Y/n]\")\n",
    "  if ans and ans.lower().startswith('n'):\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
